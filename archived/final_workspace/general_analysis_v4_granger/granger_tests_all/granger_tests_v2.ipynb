{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fslr = pd.read_csv('./data_first_solar_FSLR.csv')\n",
    "gctay = pd.read_csv('./data_siemens_gamesa_GCTAY.csv')\n",
    "spwr = pd.read_csv('./data_sunpower_SPWR.csv')\n",
    "run = pd.read_csv('./data_sunrun_RUN.csv')\n",
    "plug = pd.read_csv('./data_plug_power_PLUG.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set datatime index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_datetime_index(df):\n",
    "    df['date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df.set_index('date', inplace=True)\n",
    "    df.drop('Date', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fslr = set_datetime_index(fslr)\n",
    "gctay = set_datetime_index(gctay)\n",
    "spwr = set_datetime_index(spwr)\n",
    "run = set_datetime_index(run)\n",
    "plug = set_datetime_index(plug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fslr_normalized = pd.read_csv('./data_first_solar_FSLR_normalized.csv')\n",
    "gctay_normalized = pd.read_csv('./data_siemens_gamesa_GCTAY_normalized.csv')\n",
    "spwr_normalized = pd.read_csv('./data_sunpower_SPWR_normalized.csv')\n",
    "run_normalized = pd.read_csv('./data_sunrun_RUN_normalized.csv')\n",
    "plug_normalized = pd.read_csv('./data_plug_power_PLUG_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fslr_normalized = set_datetime_index(fslr_normalized)\n",
    "gctay_normalized = set_datetime_index(gctay_normalized)\n",
    "spwr_normalized = set_datetime_index(spwr_normalized)\n",
    "run_normalized = set_datetime_index(run_normalized)\n",
    "plug_normalized = set_datetime_index(plug_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granger Tests - FSLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlag = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=5.6362  , p=0.0177  , df_denom=2536, df_num=1\n",
      "ssr based chi2 test:   chi2=5.6428  , p=0.0175  , df=1\n",
      "likelihood ratio test: chi2=5.6366  , p=0.0176  , df=1\n",
      "parameter F test:         F=5.6362  , p=0.0177  , df_denom=2536, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=3.2807  , p=0.0378  , df_denom=2533, df_num=2\n",
      "ssr based chi2 test:   chi2=6.5743  , p=0.0374  , df=2\n",
      "likelihood ratio test: chi2=6.5658  , p=0.0375  , df=2\n",
      "parameter F test:         F=3.2807  , p=0.0378  , df_denom=2533, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=2.4702  , p=0.0602  , df_denom=2530, df_num=3\n",
      "ssr based chi2 test:   chi2=7.4310  , p=0.0594  , df=3\n",
      "likelihood ratio test: chi2=7.4201  , p=0.0596  , df=3\n",
      "parameter F test:         F=2.4702  , p=0.0602  , df_denom=2530, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=1.8753  , p=0.1120  , df_denom=2527, df_num=4\n",
      "ssr based chi2 test:   chi2=7.5281  , p=0.1105  , df=4\n",
      "likelihood ratio test: chi2=7.5169  , p=0.1110  , df=4\n",
      "parameter F test:         F=1.8753  , p=0.1120  , df_denom=2527, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.6991  , p=0.1314  , df_denom=2524, df_num=5\n",
      "ssr based chi2 test:   chi2=8.5323  , p=0.1292  , df=5\n",
      "likelihood ratio test: chi2=8.5180  , p=0.1299  , df=5\n",
      "parameter F test:         F=1.6991  , p=0.1314  , df_denom=2524, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.6448  , p=0.1308  , df_denom=2521, df_num=6\n",
      "ssr based chi2 test:   chi2=9.9197  , p=0.1281  , df=6\n",
      "likelihood ratio test: chi2=9.9004  , p=0.1289  , df=6\n",
      "parameter F test:         F=1.6448  , p=0.1308  , df_denom=2521, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.5152  , p=0.1573  , df_denom=2518, df_num=7\n",
      "ssr based chi2 test:   chi2=10.6698 , p=0.1537  , df=7\n",
      "likelihood ratio test: chi2=10.6474 , p=0.1548  , df=7\n",
      "parameter F test:         F=1.5152  , p=0.1573  , df_denom=2518, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.5353  , p=0.1397  , df_denom=2515, df_num=8\n",
      "ssr based chi2 test:   chi2=12.3657 , p=0.1356  , df=8\n",
      "likelihood ratio test: chi2=12.3356 , p=0.1368  , df=8\n",
      "parameter F test:         F=1.5353  , p=0.1397  , df_denom=2515, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=1.3811  , p=0.1908  , df_denom=2512, df_num=9\n",
      "ssr based chi2 test:   chi2=12.5243 , p=0.1853  , df=9\n",
      "likelihood ratio test: chi2=12.4934 , p=0.1869  , df=9\n",
      "parameter F test:         F=1.3811  , p=0.1908  , df_denom=2512, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.2297  , p=0.2664  , df_denom=2509, df_num=10\n",
      "ssr based chi2 test:   chi2=12.3996 , p=0.2592  , df=10\n",
      "likelihood ratio test: chi2=12.3693 , p=0.2611  , df=10\n",
      "parameter F test:         F=1.2297  , p=0.2664  , df_denom=2509, df_num=10\n"
     ]
    }
   ],
   "source": [
    "input_data = np.asarray(fslr_normalized[['closing_price','compound_sentiment']])\n",
    "test = grangercausalitytests(input_data, maxlag, addconst = True, verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.636161101099211, 0.017667746271182356, 2536.0, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1][0]['ssr_ftest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lags(test):\n",
    "    lag_found = False\n",
    "    lags = []\n",
    "    \n",
    "    for i in range(1, maxlag):\n",
    "        p = test[i][0]['ssr_ftest'][1]\n",
    "        if (p < 0.05):\n",
    "#             print('lag ' + str(i) +  ' with p = ' + str(p))\n",
    "            lags.append(test[i][0]['ssr_ftest'])\n",
    "            lag_found = True\n",
    "\n",
    "    if (lag_found == True):\n",
    "        return lags\n",
    "    else:\n",
    "        print(\"lag not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags_info = find_lags(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5.636161101099211, 0.017667746271182356, 2536.0, 1),\n",
       " (3.2806883928127704, 0.03776220147425138, 2533.0, 2)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def store_lags(granger_res_lags, lags, ticker, x2, x1):\n",
    "#     for i in lags:\n",
    "#         F = i[0]\n",
    "#         p = i[1]\n",
    "#         lag = i[3]\n",
    "#         new_row = pd.Series([F, p, lag, ticker, x2, x1], index=[\"F\", \"p\", \"lag\", \"ticker\",  \"x2\", \"x1\"])\n",
    "#         print(new_row)\n",
    "#         print(\"\\n\")\n",
    "#         granger_res_lags.append(new_row, ignore_index=True)\n",
    "    \n",
    "#     return granger_res_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_lags(granger_res_lags, lags,'FSLR', 'closing_price', 'compound_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"F\", \"p\", \"lag\", \"ticker\",  \"x2\", \"x1\"]\n",
    "granger_res_lags = pdzzzz.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['F', 'p', 'lag', 'ticker',  'x2', 'x1']\n",
    "granger_res_lags = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_rows(lags_info, ticker, x2, x1):\n",
    "    new_rows = []\n",
    "    \n",
    "    for i in lags_info:\n",
    "        F = i[0]\n",
    "        p = i[1]\n",
    "        lag = i[3]\n",
    "        new_row = [F, p, lag, ticker, x2, x1]\n",
    "        new_rows.append(new_row)\n",
    "#         new_row = pd.Series(row_list, labels)\n",
    "        print(new_row)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    return new_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.636161101099211, 0.017667746271182356, 1, 'FSLR', 'closing_price', 'compound_sentiment']\n",
      "\n",
      "\n",
      "[3.2806883928127704, 0.03776220147425138, 2, 'FSLR', 'closing_price', 'compound_sentiment']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_rows = get_new_rows(lags_info, ticker, x2, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.636161101099211,\n",
       "  0.017667746271182356,\n",
       "  1,\n",
       "  'FSLR',\n",
       "  'closing_price',\n",
       "  'compound_sentiment'],\n",
       " [3.2806883928127704,\n",
       "  0.03776220147425138,\n",
       "  2,\n",
       "  'FSLR',\n",
       "  'closing_price',\n",
       "  'compound_sentiment']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F                    5.63616\n",
      "p                  0.0176677\n",
      "lag                        1\n",
      "ticker                  FSLR\n",
      "x2             closing_price\n",
      "x1        compound_sentiment\n",
      "dtype: object\n",
      "\n",
      "\n",
      "F                    3.28069\n",
      "p                  0.0377622\n",
      "lag                        2\n",
      "ticker                  FSLR\n",
      "x2             closing_price\n",
      "x1        compound_sentiment\n",
      "dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # column_names = [\"F\", \"p\", \"lag\", \"ticker\",  \"x2\", \"x1\"]\n",
    "# # granger_res_lags = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# ticker = 'FSLR'\n",
    "# x2 = 'closing_price'\n",
    "# x1 = 'compound_sentiment'\n",
    "# labels = [\"F\", \"p\", \"lag\", \"ticker\",  \"x2\", \"x1\"]\n",
    "\n",
    "# for i in lags_info:\n",
    "#     F = i[0]\n",
    "#     p = i[1]\n",
    "#     lag = i[3]\n",
    "#     row_list = [F, p, lag, ticker, x2, x1]\n",
    "#     new_row = pd.Series(row_list, labels)\n",
    "#     print(new_row)\n",
    "#     print(\"\\n\")\n",
    "# #     granger_res_lags.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_df(df, columns, new_rows):\n",
    "    for row in new_rows:\n",
    "        row = pd.DataFrame(row, columns)\n",
    "        df.contat(row_series, ignore_index=True, axis=0)\n",
    "        print(row_series)\n",
    "        \n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'contat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-6348f256dedd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ticker'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'x2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_new_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-77-060dae6f1282>\u001b[0m in \u001b[0;36mcreate_new_df\u001b[0;34m(df, columns, new_rows)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_rows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'contat'"
     ]
    }
   ],
   "source": [
    "column_names = ['F', 'p', 'lag', 'ticker',  'x2', 'x1']\n",
    "result = pd.DataFrame(columns=column_names)\n",
    "result = create_new_df(result, column_names, new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>p</th>\n",
       "      <th>lag</th>\n",
       "      <th>ticker</th>\n",
       "      <th>x2</th>\n",
       "      <th>x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [F, p, lag, ticker, x2, x1]\n",
       "Index: []"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
